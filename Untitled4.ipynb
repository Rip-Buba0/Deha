{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11NygIBQW6KVlbco9Uxks7BaQRLzEpIJb",
      "authorship_tag": "ABX9TyO1mXZeLVPPfJ0VDhKUH0h9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rip-Buba0/Deha/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6i-K7P3YYcs",
        "outputId": "edb5fd58-9727-4196-d93f-920269c4e5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EÄŸitim seti: 2 gerÃ§ek, 2 AI\n",
            "DoÄŸrulama seti: 2 gerÃ§ek, 2 AI\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "# KlasÃ¶r yapÄ±sÄ± oluÅŸtur\n",
        "os.makedirs('dataset/train/real', exist_ok=True)\n",
        "os.makedirs('dataset/train/ai', exist_ok=True)\n",
        "os.makedirs('dataset/val/real', exist_ok=True)\n",
        "os.makedirs('dataset/val/ai', exist_ok=True)\n",
        "\n",
        "# GerÃ§ek gÃ¶rselleri topla (Ã¶rnek)\n",
        "real_images = [f for f in os.listdir('real_images') if f.endswith(('.jpg', '.png'))]\n",
        "ai_images = [f for f in os.listdir('ai_images') if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# Veriyi eÄŸitim ve doÄŸrulama setlerine ayÄ±r\n",
        "real_train, real_val = train_test_split(real_images, test_size=0.2, random_state=42)\n",
        "ai_train, ai_val = train_test_split(ai_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# DosyalarÄ± kopyala\n",
        "def copy_files(files, src_dir, dest_dir):\n",
        "    for f in files:\n",
        "        src_path = os.path.join(src_dir, f)\n",
        "        try:\n",
        "            Image.open(src_path)\n",
        "            shutil.copy(src_path, dest_dir)\n",
        "        except:\n",
        "            print(f\"Skipping corrupted file: {src_path}\")\n",
        "\n",
        "copy_files(real_train, 'real_images', 'dataset/train/real')\n",
        "copy_files(real_val, 'real_images', 'dataset/val/real')\n",
        "copy_files(ai_train, 'ai_images', 'dataset/train/ai')\n",
        "copy_files(ai_val, 'ai_images', 'dataset/val/ai')\n",
        "\n",
        "print(f\"EÄŸitim seti: {len(os.listdir('dataset/train/real'))} gerÃ§ek, {len(os.listdir('dataset/train/ai'))} AI\")\n",
        "print(f\"DoÄŸrulama seti: {len(os.listdir('dataset/val/real'))} gerÃ§ek, {len(os.listdir('dataset/val/ai'))} AI\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab Optimized AI Image Detector Training\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, applications\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint,\n",
        "                                       EarlyStopping,\n",
        "                                       ReduceLROnPlateau)\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Google Drive'Ä± baÄŸla\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Veri seti yollarÄ±nÄ± ayarla\n",
        "dataset_path = '/content/dataset'  # Corrected path\n",
        "TRAIN_DIR = os.path.join(dataset_path, 'train')\n",
        "VAL_DIR = os.path.join(dataset_path, 'val')\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 3. Veri artÄ±rma\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# 4. Veri yÃ¼kleyiciler\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    VAL_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 5. Model oluÅŸturma (EfficientNetB3)\n",
        "def create_model():\n",
        "    base_model = applications.EfficientNetB3(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "        pooling='avg'\n",
        "    )\n",
        "\n",
        "    # Fine-tuning\n",
        "    for layer in base_model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "        base_model,\n",
        "        layers.Dense(1024, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# 6. Callback'ler\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/drive/MyDrive/models/best_model.h5',\n",
        "    monitor='val_auc',\n",
        "    save_best_only=True,\n",
        "    mode='max'\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.3,\n",
        "    patience=5,\n",
        "    min_lr=1e-7\n",
        ")\n",
        "\n",
        "# 7. Model eÄŸitimi\n",
        "print(\"EÄŸitim baÅŸlÄ±yor...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
        "    epochs=50,\n",
        "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "# 8. Modeli kaydet\n",
        "model.save('/content/drive/MyDrive/models/final_model.h5')\n",
        "print(\"EÄŸitim tamamlandÄ± ve model Drive'a kaydedildi!\")\n",
        "\n",
        "# 9. TensorFlow.js dÃ¶nÃ¼ÅŸÃ¼mÃ¼\n",
        "!pip install tensorflowjs\n",
        "!mkdir -p '/content/drive/MyDrive/models/tfjs_model'\n",
        "!tensorflowjs_converter \\\n",
        "    --input_format=keras \\\n",
        "    '/content/drive/MyDrive/models/final_model.h5' \\\n",
        "    '/content/drive/MyDrive/models/tfjs_model'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP0mKhQaYdZf",
        "outputId": "734f4ea6-88a3-45c5-b335-c7dff63efa78"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 4 images belonging to 2 classes.\n",
            "Found 4 images belonging to 2 classes.\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.3047"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 112s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.3047 - val_accuracy: 0.5000 - val_auc: 1.0000 - val_loss: 0.6985 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.3491 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7016 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.2319 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7046 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0619 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7081 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.2684 - val_accuracy: 0.5000 - val_auc: 1.0000 - val_loss: 0.7121 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0323 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7152 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0347 - val_accuracy: 0.5000 - val_auc: 1.0000 - val_loss: 0.7116 - learning_rate: 3.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0493 - val_accuracy: 0.5000 - val_auc: 1.0000 - val_loss: 0.7055 - learning_rate: 3.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0079 - val_accuracy: 0.5000 - val_auc: 1.0000 - val_loss: 0.7040 - learning_rate: 3.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0104 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7084 - learning_rate: 3.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0042 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7095 - learning_rate: 3.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EÄŸitim tamamlandÄ± ve model Drive'a kaydedildi!\n",
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.11/dist-packages (4.22.0)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.10.6)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (6.5.2)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.5.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.5.1)\n",
            "Requirement already satisfied: tensorflow<3,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: tf-keras>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-decision-forests>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: six<2,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.16.1)\n",
            "Requirement already satisfied: packaging~=23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (23.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (2.0.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (1.1.1)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.2.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.11.19)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.74)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (4.14.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.9)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (18.1.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (75.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.14.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.37.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.45.1)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: ydf in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.13.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2025.7.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.19.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.1.3)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.90)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.13.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax->flax>=0.7.2->tensorflowjs) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2025.3.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.23.0)\n",
            "2025-07-28 12:23:12.626839: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753705392.911735   47602 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753705392.990476   47602 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[32mðŸŒ² Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n",
            "failed to lookup keras version from the file,\n",
            "    this is likely a weight only file\n",
            "weight normalization_3/count with shape () and dtype int64 was auto converted to the type int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli optimize etme\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# TFLite modelini kaydet\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# TensorFlow.js iÃ§in quantize etme\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "# Float16 quantizasyonu\n",
        "tfjs.converters.save_keras_model(\n",
        "    model,\n",
        "    'tfjs_quantized_model'\n",
        ")\n",
        "\n",
        "print(\"Quantize edilmiÅŸ model kaydedildi!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xA7sVxmYeSt",
        "outputId": "856bab67-d95a-4617-c1ba-ffa0f4abd186"
      },
      "execution_count": 36,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpf4s5elgp'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name='keras_tensor_2935')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137337309712016: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
            "  137337309709136: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
            "  137337199724304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199723152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199727760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199729680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199724496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199728720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200088976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200097232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200097040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200093968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200094160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200093008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200096464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200093776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200098192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200089360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200089936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200092240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200091856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200086672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200087824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200083600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200085904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200093200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200098768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200089744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200084176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200391952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200385616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200392912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200390416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200390608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200391760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200390800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200386384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200384656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200386960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200387920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200383504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200382928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200381584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200382352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200386000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200379664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200380624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200379280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200388880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199787664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199786320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199783824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199785744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199783056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199781904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199784016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199780176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199782480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199787856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199779024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199778448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199777104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199777872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199785360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199775184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199774032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199778640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199774224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199771728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200524176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200522832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199785168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337199772880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200522064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200520336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200518992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200521104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200523408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200517648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200518032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200515728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200515152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200521488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200513808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200512464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200515536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200509200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200510736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200510544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081379536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200510352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337200511888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081380688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081377040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081374352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081376464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081380112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081372816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081374928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081370896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081373392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081378384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081369168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081367824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081372240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081367440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081375120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081365328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081366096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081368016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081368976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081511376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081511568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081507152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081509072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081509840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081505616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081507728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081503696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081506192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081510992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081501968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081500624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081505040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081500240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081509264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081498320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081496976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081500432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081499664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081501776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081740944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081726352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081740368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081726160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081736336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081738064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081734416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081736720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081738640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081730768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081740176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081729424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081730000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081732880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081725392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081737296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081729616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081728848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081736912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081725776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081725584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081733072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337081726928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338920400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338916944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338919824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338920592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338919632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338919248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338916176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338920208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338917904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338920784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338914256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338912336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338914640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338917520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338911568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338912144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338908880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338910992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338913872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338906576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338909456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337922969168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338906000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338918288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338905616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338904656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337338909648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205323152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205324304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205325648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205321808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205322768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205323728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205323344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205319504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205315856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205318160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205320656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205313552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205315280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205311632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205313936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205318736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205310288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205312016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205311440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205318928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205317584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205374608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205371344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205371728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205373648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205372688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205367120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205366352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205369040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205372304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205364816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205366928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205362896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205365392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205370384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205361168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205359056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205364240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205368464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205360976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205361744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205571024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337842280848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205370192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205570448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205568720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205565072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205567376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205570064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205562768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205564496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205560848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205563152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205567952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205560080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205559504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205563728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205559312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137338121265680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205568144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205566800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205557200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337205557968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906589648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906588688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906592912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906590800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906587920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906593680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906591952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906593872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906594064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906589264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137338061375248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337856083920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337926602384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906590224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137336906590992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337747711056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337747717584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337722042320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337722033488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337983685968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337747710288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337747702416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337847937552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337747712592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337428560016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337428566160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337428570000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337428568080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337428572688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337439737552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337439741392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337439739472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337439739088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337439747920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337434001808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337434011408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337439743312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337434004496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337434012176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337435803856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337849749456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337435803088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337435800208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337916027344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337435814224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337571541840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337860058640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337571551056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337977947920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337435805392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337571542224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337573431568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337573428496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337718541392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337575248464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337573436944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337569778320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337914323216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337569780624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337852476880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337569775632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337711400848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337908738384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337852470352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295476432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337575250000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337707838736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295486032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295474512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295481808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295482192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295474896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295485648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295474128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295476048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295481424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337985448080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337910452176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295484496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137338064988560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337295471824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293765520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293763600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293766288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293754000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293763216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293753616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293760912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293758224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293752848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293763984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443285328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443281104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337293751696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443278032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443284176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443286864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443270736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443283024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443281488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443286096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297331856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297334160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337443280720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297332624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297324176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297327632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297337232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297325328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297324560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297330704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301168976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297329936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337297336848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301171664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301156688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301168016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301161296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301171280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301160144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301165520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441432592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301160912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337301170512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441420304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441430288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441427216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441427600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441432208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441419344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441426064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441424528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337441424144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613529552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613532624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613524944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613526480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613519184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613533008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613523024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613529168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613523792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613521104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337613525328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337445087760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337445081232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337445078160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337445088912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337445073360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337445083152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337445080080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337445083536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337445082768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337346114000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337346129360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337346122064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337346123600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337346113616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337346117648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337346121680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337346113808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337346127632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337844340048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337716562192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137338130712144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337716559120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337928728656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337716559888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334435280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337702166416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337716566032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334433552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334441232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334444112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334434704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334432784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334444880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334443920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334446416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334446800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334436432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334443152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334437776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334445072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334437200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334443728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334435664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182991888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334432400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337334437392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182996304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182997456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182990736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339183002832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182995536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182993040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339183004944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182993616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339183004368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182997648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182996496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339183000912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137339182992464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302255952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302262096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302254800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302261904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302258832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302260560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302259984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302263824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207062160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302268624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337302269392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207054288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207050448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207052368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207052944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207055248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207056208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207054672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207052752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207055056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207060240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207047184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207048912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207058704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207057744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207047760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309512336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309513488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207049104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337207056400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309515216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309517136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309516944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309517520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309513296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309518864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309520400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309518288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309522320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309513680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309522512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309523856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309524432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309523664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309524816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309527312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309708944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309527504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309526160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309708368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309715856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309713360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309711824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309712400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309715088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309719312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137337309719696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "failed to lookup keras version from the file,\n",
            "    this is likely a weight only file\n",
            "weight normalization_3/count with shape () and dtype int64 was auto converted to the type int32\n",
            "Quantize edilmiÅŸ model kaydedildi!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "def build_model(hp):\n",
        "    base_model = EfficientNetB0(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=IMG_SIZE + (3,)\n",
        "    )\n",
        "\n",
        "    # Fine-tuning katman sayÄ±sÄ±\n",
        "    unfreeze_layers = hp.Int('unfreeze_layers', 10, 30, step=5)\n",
        "    for layer in base_model.layers[-unfreeze_layers:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(hp.Int('units1', 512, 2048, step=256), activation='relu')(x)\n",
        "    x = Dropout(hp.Float('dropout1', 0.3, 0.7, step=0.1))(x)\n",
        "    x = Dense(hp.Int('units2', 256, 1024, step=128), activation='relu')(x)\n",
        "    x = Dropout(hp.Float('dropout2', 0.2, 0.5, step=0.1))(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(hp.Choice('learning_rate', [1e-4, 5e-5, 1e-5])),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_auc',\n",
        "    max_trials=15,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuning',\n",
        "    project_name='ai_detector'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    callbacks=[EarlyStopping(patience=5)]\n",
        ")\n",
        "\n",
        "# En iyi modeli al\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8LpxMAWYgzc",
        "outputId": "c4e4b1dd-a078-4ca2-e3b3-e9353d946535"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Reloading Tuner from tuning/ai_detector/tuner0.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 436 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuW8B2-hoBtS",
        "outputId": "5f1c3d4e-3997-4e81-f055-9502014ee70e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def load_model(model_path):\n",
        "    try:\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "        print(\"âœ… Model successfully loaded\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "def preprocess_image(img_path, target_size=(224, 224)):\n",
        "    \"\"\"Preprocess image to match model training parameters\"\"\"\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0  # Normalize to [0,1]\n",
        "    return img_array\n",
        "\n",
        "def predict_ai(model, img_array):\n",
        "    \"\"\"Make prediction and return confidence score\"\"\"\n",
        "    try:\n",
        "        prediction = model.predict(img_array)\n",
        "        return prediction[0][0]  # Return the probability score\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Prediction error: {e}\")\n",
        "        return 0.5  # Return neutral value on error\n",
        "\n",
        "def verify_model(model):\n",
        "    \"\"\"Test model with known samples to verify predictions\"\"\"\n",
        "    print(\"\\nðŸ§ª Running model verification tests...\")\n",
        "\n",
        "    # Create simple test images (black and white)\n",
        "    black_img = np.zeros((224, 224, 3))\n",
        "    white_img = np.ones((224, 224, 3)) * 255\n",
        "\n",
        "    # Preprocess\n",
        "    black_array = np.expand_dims(black_img, axis=0) / 255.0\n",
        "    white_array = np.expand_dims(white_img, axis=0) / 255.0\n",
        "\n",
        "    # Predict\n",
        "    black_score = model.predict(black_array)[0][0]\n",
        "    white_score = model.predict(white_array)[0][0]\n",
        "\n",
        "    print(f\"  Black image score: {black_score:.4f}\")\n",
        "    print(f\"  White image score: {white_score:.4f}\")\n",
        "\n",
        "    if abs(black_score - white_score) < 0.1:\n",
        "        print(\"âš ï¸ Warning: Model predictions are similar for very different images\")\n",
        "        print(\"This suggests the model might not be functioning correctly\")\n",
        "    else:\n",
        "        print(\"âœ… Model shows variation in predictions\")\n",
        "\n",
        "def analyze_predictions(model, image_folder):\n",
        "    \"\"\"Analyze predictions for all images in a folder\"\"\"\n",
        "    print(f\"\\nðŸ” Analyzing predictions in {image_folder}\")\n",
        "    class_counts = {'real': 0, 'ai': 0}\n",
        "    scores = []\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img_path = os.path.join(image_folder, filename)\n",
        "            processed_img = preprocess_image(img_path)\n",
        "            ai_score = predict_ai(model, processed_img)\n",
        "\n",
        "            # Store results\n",
        "            scores.append(ai_score)\n",
        "            prediction = \"ai\" if ai_score > 0.8 else \"real\"\n",
        "            class_counts[prediction] += 1\n",
        "\n",
        "            print(f\"  {filename}: {prediction} ({ai_score:.4f})\")\n",
        "\n",
        "    print(f\"\\nðŸ“Š Prediction distribution:\")\n",
        "    print(f\"  AI predictions: {class_counts['ai']}\")\n",
        "    print(f\"  Real predictions: {class_counts['real']}\")\n",
        "    if scores:\n",
        "        print(f\"  Average score: {np.mean(scores):.4f}\")\n",
        "        print(f\"  Score range: {min(scores):.4f} - {max(scores):.4f}\")\n",
        "    else:\n",
        "        print(\"  No images found in the test folder.\")\n",
        "\n",
        "    if len(set(scores)) < 2 and len(scores) > 1:\n",
        "        print(\"âš ï¸ Warning: All predictions are identical!\")\n",
        "        print(\"This indicates a problem with the model or data\")\n",
        "\n",
        "# Main workflow\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    MODEL_PATH = 'best_model.h5'\n",
        "    TEST_IMAGE = 'ai_images/ai1.png'\n",
        "    TEST_FOLDER = 'Untitled Folder/test_images/'  # Folder with multiple test images\n",
        "\n",
        "    # Load model\n",
        "    model = load_model(MODEL_PATH)\n",
        "\n",
        "    if model is None:\n",
        "        print(\"âŒ Exiting due to model loading error\")\n",
        "        exit(1)\n",
        "\n",
        "    # Verify model with test patterns\n",
        "    verify_model(model)\n",
        "\n",
        "    # Analyze predictions on multiple images\n",
        "    analyze_predictions(model, TEST_FOLDER)\n",
        "\n",
        "    # Test with a specific image\n",
        "    print(f\"\\nðŸ”Ž Testing with {TEST_IMAGE}\")\n",
        "    if os.path.exists(TEST_IMAGE):\n",
        "        processed_img = preprocess_image(TEST_IMAGE)\n",
        "        ai_score = predict_ai(model, processed_img)\n",
        "\n",
        "        # Show the image\n",
        "        img = image.load_img(TEST_IMAGE)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Display prediction results\n",
        "        print(f\"\\nAI Probability Score: {ai_score:.4f}\")\n",
        "        if ai_score > 0.8:\n",
        "            print(\"Prediction: This image is AI-generated\")\n",
        "            plt.title(f\"AI-Generated ({ai_score:.2%})\", color='red')\n",
        "        elif ai_score < 0.2:\n",
        "            print(\"Prediction: This is a real image\")\n",
        "            plt.title(f\"Real Image ({1-ai_score:.2%})\", color='green')\n",
        "        else:\n",
        "            print(\"Prediction: Uncertain (model confidence is low)\")\n",
        "            plt.title(f\"Uncertain ({ai_score:.2%})\", color='orange')\n",
        "\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Test image not found at: {TEST_IMAGE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "id": "XnajmMKaYi-r",
        "outputId": "1afbb972-5940-44d5-971d-f1e92f881d2f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model successfully loaded\n",
            "\n",
            "ðŸ§ª Running model verification tests...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step\n",
            "  Black image score: 0.4979\n",
            "  White image score: 0.4993\n",
            "âš ï¸ Warning: Model predictions are similar for very different images\n",
            "This suggests the model might not be functioning correctly\n",
            "\n",
            "ðŸ” Analyzing predictions in Untitled Folder/test_images/\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
            "  test.png: real (0.4985)\n",
            "\n",
            "ðŸ“Š Prediction distribution:\n",
            "  AI predictions: 0\n",
            "  Real predictions: 1\n",
            "  Average score: 0.4985\n",
            "  Score range: 0.4985 - 0.4985\n",
            "\n",
            "ðŸ”Ž Testing with ai_images/ai1.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "\n",
            "AI Probability Score: 0.4957\n",
            "Prediction: Uncertain (model confidence is low)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddf74be2"
      },
      "source": [
        "import os\n",
        "os.makedirs('real_images', exist_ok=True)\n",
        "os.makedirs('ai_images', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1db6b45b"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Create blank images\n",
        "for i in range(1, 3):\n",
        "    Image.new('RGB', (100, 100), color = 'red').save(f'real_images/real{i}.jpg')\n",
        "    Image.new('RGB', (100, 100), color = 'blue').save(f'ai_images/ai{i}.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f61bf507"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def clean_directory(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        if os.path.isfile(filepath):\n",
        "            try:\n",
        "                Image.open(filepath)\n",
        "            except:\n",
        "                print(f\"Removing non-image file: {filepath}\")\n",
        "                os.remove(filepath)\n",
        "\n",
        "clean_directory('real_images')\n",
        "clean_directory('ai_images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "def clean_dataset(dataset_path):\n",
        "    for class_dir in ['real', 'ai']:\n",
        "        dir_path = os.path.join(dataset_path, class_dir)\n",
        "        for filename in os.listdir(dir_path):\n",
        "            file_path = os.path.join(dir_path, filename)\n",
        "\n",
        "            # BoÅŸ dosya kontrolÃ¼\n",
        "            if os.path.getsize(file_path) == 0:\n",
        "                print(f\"BoÅŸ dosya siliniyor: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                continue\n",
        "\n",
        "            # GeÃ§erli gÃ¶rsel kontrolÃ¼\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()  # GÃ¶rsel doÄŸrulama\n",
        "            except (IOError, SyntaxError) as e:\n",
        "                print(f\"GeÃ§ersiz gÃ¶rsel siliniyor: {file_path} - Hata: {str(e)}\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "# EÄŸitim ve doÄŸrulama setlerini temizle\n",
        "clean_dataset('dataset/train')\n",
        "clean_dataset('dataset/val')\n",
        "\n",
        "print(\"Veri seti temizleme tamamlandÄ±!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mwwX4MLf_Tu",
        "outputId": "9c312554-7907-4864-97c3-ab3f0f041f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoÅŸ dosya siliniyor: dataset/val/real/real2.png\n",
            "BoÅŸ dosya siliniyor: dataset/val/ai/ai1.jpg\n",
            "Veri seti temizleme tamamlandÄ±!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c29cf77c",
        "outputId": "2fc88f0e-4eaa-41ae-d49a-d11b75ba26bc"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.22.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.10.6)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (6.5.2)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.5.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.13 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.5.1)\n",
            "Requirement already satisfied: tensorflow<3,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: tf-keras>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-decision-forests>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: six<2,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (1.17.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from tensorflowjs) (0.16.1)\n",
            "Collecting packaging~=23.1 (from tensorflowjs)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (2.0.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (1.1.1)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.2.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.11.19)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.74)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (4.14.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.9)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.13->tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (18.1.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (75.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.14.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.37.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.45.1)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: ydf in /usr/local/lib/python3.11/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.13.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2025.7.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.19.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.1.3)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.90)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.13.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2025.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax->flax>=0.7.2->tensorflowjs) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2025.3.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.23.0)\n",
            "Downloading tensorflowjs-4.22.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m667.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: packaging, tensorflowjs\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2025.7.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "google-cloud-bigquery 3.35.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed packaging-23.2 tensorflowjs-4.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              },
              "id": "bda93dead4ba4e1e94f2cab2650bf1a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "def clean_dataset(dataset_path):\n",
        "    for class_dir in ['real', 'ai']:\n",
        "        class_path = os.path.join(dataset_path, class_dir)\n",
        "\n",
        "        # Skip if class directory doesn't exist\n",
        "        if not os.path.exists(class_path):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(class_path):\n",
        "            file_path = os.path.join(class_path, filename)\n",
        "\n",
        "            # Skip directories (only process files)\n",
        "            if not os.path.isfile(file_path):\n",
        "                continue\n",
        "\n",
        "            # Check for empty files\n",
        "            if os.path.getsize(file_path) == 0:\n",
        "                print(f\"Deleting empty file: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                continue\n",
        "\n",
        "            # Validate image format\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()  # Verify image integrity\n",
        "            except (IOError, SyntaxError, OSError) as e:\n",
        "                print(f\"Deleting corrupt/invalid image: {file_path} - Error: {str(e)}\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "# Clean both training and validation datasets\n",
        "clean_dataset('dataset/train')\n",
        "clean_dataset('dataset/val')\n",
        "\n",
        "print(\"Dataset cleaning completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUFwVXmDgxfC",
        "outputId": "1397d7cd-4810-4da8-dfc5-277eb7fe8c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cleaning completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a67d039a"
      },
      "source": [
        "import os\n",
        "os.makedirs('Untitled Folder/test_images', exist_ok=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53856314"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Create a blank image and save it to the test folder\n",
        "Image.new('RGB', (100, 100), color = 'green').save('Untitled Folder/test_images/test.png')"
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}